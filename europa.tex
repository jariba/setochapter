\subsection{Architecture}
\label{sec:europa:arch}

\eu is implemented as a library that encapsulates all elements
\kcomment{previously described} and available via modeling and
Application Programming Interfaces (APIs).  A user will typically use
modeling facilities to inject a problem domain description and the API
to extract and manipulate plans and to obtain information about plan
flaws and constraint violations at any stage of the planning process.

\begin{figure}[b]
\centering
\includegraphics[scale=0.5]{figs/EUROPA-Architecture.pdf}
\caption{\small The \eu software architecture.}
\label{fig:europa-architecture}
\end{figure}

Fig. \ref{fig:europa-architecture} shows the main architectural
components in \eu and their relationships. The \textbf{Constraint
  Reasoning Engine} (\texttt{CRE}) manages domain types, variables and
constraints that define relationships among them. It also provides an
efficient arc consistency mechanism \cite{mackworth77} designed so
that specialized reasoning algorithms for new constraints can be
easily and efficiently plugged in. The \textbf{Plan Database}
(\texttt{PDB}) manages object and token types. It also maintains the
state of partial plans in terms of object, variable and token
instances. This constitutes the data foundation on which end user
applications and automated problem solvers are built. The
\textbf{Rules Engine} (\texttt{RE}) adds the semantics of domain rules
that describe dependencies between tokens. The \textbf{Solver Module}
provides the framework for flaw detection and resolution that is
needed to implement search algorithms for planning. The \textbf{API
  Layer} provides access to services from all the different modules in
a programmatic way so that \eu can be easily embedded into specialized
applications.

Describing problem domains and problem instances in terms of objects,
variables and domain rules is cumbersome to the extent of being
impractical; this motivated the creation of modeling languages that
support those definitions in a much more natural and compact way. \nd
(New Domain Description Language [pronounced ``noodle'']) \cite{NDDL}
is the \kcomment{primary} modeling language for \eu described in
Section \ref{sec:europa:modeling}. Another, \texttt{ANML}
\cite{smith08} is a language under development that provides a more
intuitive syntax \kcomment{and out of scope for this chapter}.
  
In an effort to mimimize the amount of work that a user needs to
perform to solve specific problems, \eu also bundles extension
modules that have been found to be useful in many domains:

\begin{enumerate}

\item \textit{Temporal Network}: Extensions to the \texttt{CRE} module to
  reason about temporal constraints.

\item \textit{Resources}: Extensions to the \texttt{CRE}, \texttt{PDB}
  and \textbf{Solver Module} to provide reasoning and search for
  metric resources.

\item \textit{Chronological Backtracking Solver}: A general purpose
  built-in solver to provide the ability to plan out-of-the-box.
  Problems that require challenging search may require specialized
  solvers to be built as noted in Section \ref{sec:europa:search}.

\end{enumerate}

\kcomment{Before going into the details of each module, a simple
  example illustrates how they interact at an abstract level:}

\begin{verbatim}

class LightBulb extends Timeline
{
    predicate On  {}
    predicate Off {}
}

class LightSwitch extends Timeline
{
    LightBulb myBulb_;

    LightSwitch(LightBulb b)
    {
        myBulb_ = b;
    }

    action turnOn  { duration=1; }
    action turnOff { duration=1; }
}

LightSwitch::turnOn
{
    met_by(condition object.myBulb_.Off);  // Bulb must be Off to be turned On
    meets(effect object.myBulb_.On);   // Must be turned on through the switch
}

LightSwitch::turnOff
{
    met_by(condition object.myBulb_.On);   // Bulb must be On to be turned Off
    meets(effect object.myBulb_.Off);      // Must be turned off through the switch
}

// Problem instance : turning the light off
LightBulb bulb1 = new LightBulb();
LightSwitch switch1 = new LightSwitch(bulb1);

// At time 0, the bulb is on
fact(bulb1.On initialCondition);
eq(initialCondition.start,0);

// We want the bulb to be off by time 10
goal(bulb1.Off goal1);
lt(0,goal1.start);
lt(goal1.start,10);


\end{verbatim}

\kcomment{The example above is a \nd (covered in more detail in
  Section \ref{sec:europa:modeling}) model of a light bulb and a
  switch that controls it along with a problem instance that requires
  the light bulb to be \texttt{off} by time$=10$, given an initial
  state with the bulb \texttt{on} at time$=0$. The \nd module allows
  \eu to ingest this model and the problem description. Once the \nd
  statements are parsed, different object types, object instances and
  constraints are instantiated inside the \texttt{PDB} and
  \texttt{CRE} modules where they are available for the user and the
  solver modules to query and manipulate programmatically. This
  instantiation of the initial state constitutes the initial plan that
  \eu holds for this particular problem instance.
 
  The user can then invoke functionality available in the solver
  module to modify or extend this initial plan in a way that
  eliminates any flaws (violated constraints, unsatisfied goals,
  oversubscribed resources). When actions are added to a plan, the
  \texttt{RE} ensures that domain rules expressed in the model are
  enforced when \eu creates new action or predicate instances. For
  instance, if a \texttt{LightSwitch::turnOn} action is added to the
  plan, the \texttt{RE} ensures that requirements for the existence of
  the conditions and effects of that action (that is, the
  corresponding \texttt{LightBulb} must be off before and on after the
  action) are posted through the \texttt{PDB} and \texttt{CRE}
  modules.  }

\subsection{Modeling in \eu}
\label{sec:europa:modeling}

\eu can ingest descriptions of models, plans and goals and thereby can
be applied to different domains and problems, simply by providing
different models and goals. Consequently the expressiveness of the
language for models, goals and plans is of great importance. For \eue,
\nd allows the user to specify the different components of a problem
domain in a precise and concise manner. Among the main features that
make \nd a powerful tool for describing problem domains are that it is
object oriented. It supports classes and inheritance in similar
fashion to popular object-oriented languages like Java and C++. It
also supports polymorphism for some planning components. Using object
classes and instances is a time-tested approach to naturally describe
problem domains \cite{rumbaugh}. It offers declarative constructs to
define constraints and causality dependencies between actions and
effects and it offers procedural constructs to populate \eus
\texttt{PDB} with specific problem instances expressed in terms of
objects, variables, constraints, facts and goals. 

To articulate the most important elements of \nde, we show how the
Shopping Agent problem could be modeled:

\begin{verbatim}

// Locations (Home, SuperMarket, etc.)
class Location {
  string name;
  Location(string _name){
    name = _name;
  }
}

// Products (Milk, Banana, etc.) and
class Product {
  string name;
  Product(string _name) {
    name = _name;
  }
}

// ProductLocations (Banana can be found at SuperMarket, for example)
class ProductLocation {
  Location location;
  Product product;

  ProductLocation(Location _location, Product _product){
    location = _location;
    product = _product;
  }
}

// Use built-in Timeline functionality to enforce that an agent:
// a) Can't be at more than one place at a time.
// b) Can't Go more than one place at a time.
// c) Can't Go somewhere and be At somewhere at the same time.
class AgentLocation extends Timeline{
  predicate At {
    Location loc;
  }

  predicate Going {
    Location from;
    Location to;
  }
}

// In addition to having a location timeline, the agent can buy and own things.  
// Note that the actions and the location predicates can be concurrent 
// so they can't be on the same Timeline
class Agent {
  AgentLocation location;

  Agent() {
    location = new AgentLocation();
  }

  action Buy {
    Product product;
  }
  
  action Go {
    Location from;
    Location to;
  }
  
  predicate Own {
  	Product product;
  }
}
\end{verbatim}

The model above the main elements of a problem domain can be mapped to
\eus representation in the \kcomment{following manner}:

\begin{description}

\item[\textbf{Object Types}:] \nd supports an object-oriented
  approach, where common data and behavior can be abstracted as a
  class. In this case, we have the \textit{Product} class represent
  the products that the Shopping Agent needs, \textit{Location}
  represents the places where products can be found,
  \textit{ProductLocation} represents the association arising when a
  product can be purchased at a location. The Shopping Agent itself is
  represented by an \textit{Agent} class, which relies on the
  \textit{AgentLocation} class to keep track of where the agent is at
  any point in time. \nd supports a single rooted class hierarchy so
  that state and behavior can be extended through inheritance. We take
  advantage of that feature by making \textit{AgentLocation} inherit
  from \eus built-in \textit{Timeline} class which does not allow
  predicates to overlap in time for the same object instance. This
  feature is used for instance, to ensure that an agent can only be at
  one place at a time in our example.

\item[\textbf{Variable Types and Instances}:] All object attributes
  are represented as variables in this model. For instance, it uses
  integer variables to represent the built-in temporal parameters for
  each token (duration, start and end times), string
  variables to represent \textit{Location} and \textit{Product} names,
  and object reference variables to represent the structural
  relationships between different objects (for instance, each Agent
  maintains a variable to keep track of its \textit{AgentLocation}).

\item[\textbf{Predicate Types}:] Some classes like \textit{Product},
  \textit{Location} and \textit{ProductLocation} are static and so
  don't have any predicate or action types associated with them. The
  \textit{AgentLocation} class is used to keep track of state and so
  has \texttt{At} and \texttt{Going} predicate types associated with
  it. The \textit{Agent} class keeps track of the products it
  purchases through the \texttt{Own} predicate; having a separate
  \textit{AgentBag} class with its own predicates would have been an
  equally valid modeling choice.

\item[\textbf{Action Types}:] In our example, \textit{Agent} is solely
  the class that has behavior associated with it. Consequently, it
  defines action types to represent when the agent is taking action to
  \texttt{Go} to a \textit{Location}, or to \texttt{Buy} a
  \textit{Product}. 
  
\end{description}

\begin{verbatim}

// Define the rules for our actions:
Agent::Go {
  met_by(condition object.location.At origin);
  eq(from, origin.loc);
 
  equals(effect object.location.Going going);
  eq(going.from, from);
  eq(going.to, to);
   
  meets(effect object.location.At destination);
  eq(to, destination.loc);
}

Agent::Buy {
  // A Buy takes 10 time units
  eq(10, duration);

  // initialized to all locations
  ProductLocation possibleStores;

  // limit possibleStores variables to ones that provide what we need to buy
  eq(product, possibleStores.product);

  // We must be At a location during our Buy, and that location must have the
  // product we want available:
  contained_by(condition object.location.At currLocation);
  eq(currLocation.loc, possibleStores.location);
  
  meets(effect Own purchase);
  eq(purchase.product,product);
}
\end{verbatim}

Domain rules can be defined in \nd in the context of a predicate or an
action. In the example above, the main elements of a rule definition
\kcomment{are as follows}:

\begin{description}

\item[\textbf{Variables}:] A token type (predicate or action) is part
  of a class, therefore class attributes (see \texttt{object.location}
  above), token type parameters (see \texttt{[from, to]} in
  \texttt{Agent::Go}, or \texttt{[duration, product]} in
  \texttt{Agent::Buy}) and locally declared variables (see
  \texttt{possibleStores} in \texttt{Agent::Buy}) can all be used in
  the definition of a rule.

\item[\textbf{Constraints}:] Restrictions on values that variables can
  take within a rule are expressed through constraints. In the example
  above the \texttt{eq} constraint is used; in general, any constraint
  available in \eus library can be used.

\item[\textbf{Subgoals}:] In \texttt{Agent::Go}, subgoals are used to
  specify that the Shopping Agent's location must transition from
  origin to destination in a temporally consistent way. The
  \texttt{[meets, equals, metby]} operators (see Section
  \ref{sec:europa:inference}) are used to specify subgoals, along with
  the temporal relationship each token representing a subgoal has with
  the the token representing the \texttt{Agent::Go} action. Also,
  \texttt{[condition, effect]} annotations can be used when defining a
  subgoal inside an action. \eu does not intrinsicaly associate semantics
  with these annotations; but they can be extremely useful for search
  modules when creating plans.

\end{description}

With the specification for the Shopping Agent domain \kcomment{above},
a particular problem instance could be stated as:

\begin{verbatim}

// Allocate instances
Location Home = new Location("Home");
Location SuperMarket = new Location("SuperMarket");
Location HardwareStore = new Location("HardwareStore");

Product Banana = new Product("Banana");
Product Milk = new Product("Milk");
Product Drill = new Product("Drill");

ProductLocation bananaLocation = new ProductLocation(SuperMarket, Banana);
ProductLocation milkLocation = new ProductLocation(SuperMarket, Milk);
ProductLocation drillLocation = new ProductLocation(HardwareStore, Drill);

Agent agent = new Agent();

// Indicate that the database is closed - no new objects can be created
// this allows EUROPA to perform more efficient inference
close();

// We start the day at Home:
fact(agent.location.At atHomeForBreakfast);
atHomeForBreakfast.loc.specify(Home);

// Goals for all of the agent's needs, buy if needed
goal(agent.Own gotMilk);
gotMilk.product.specify(Milk);
goal(agent.Own gotBanana);
gotBanana.product.specify(Banana);
goal(agent.Own gotDrill);
gotDrill.product.specify(Drill);

// Make sure agent is home for dinner
goal(agent.location.At atHomeForDinner);
atHomeForDinner.loc.specify(Home);

// Agent has all day to satisfy goals:
gotMilk after atHomeForBreakfast;
gotMilk before atHomeForDinner;

gotBanana after atHomeForBreakfast;
gotBanana before atHomeForDinner;

gotDrill after atHomeForBreakfast;
gotDrill before atHomeForDinner;

// Force things to happen within our planning horizon:
int horizonStart = 0;
int horizonEnd = 100;
leq(horizonStart, atHomeForBreakfast.start);
leq(atHomeForDinner.end, horizonEnd);

\end{verbatim}

This problem instance consists of \textbf{Variables} and
\textbf{Objects}, \textbf{Facts}, \textbf{Goals} and
\textbf{Constraints}. In our example we define temporal variables that
are used to specify the planning horizon (\texttt{horizonStart} and
\texttt{horizonEnd}) and objects are used to specify locations,
products, product-location associations and the Shopping Agent that we
want to plan for. Facts, represented as tokens in the \texttt{PDB},
are used to specify the current state of the world \kcomment{and} do
not need any support. In this \kcomment{example} we use facts to
specify that the Shipping Agent is initially at home. Goals are also
represented as tokens in the \texttt{PDB}. Different from facts, goals
trigger inference in \eu which determine whether flaws (unresolved
subgoals, overloaded resources, etc.) need to be resolved; if so,
search modules can be invoked to resolve those flaws as part of the
deliberation process. Finally, constraints are restrictions on and
between facts and goals. In the example above, we use temporal
constraints to specify when facts hold and when goals need to be
accomplished. \texttt{before} and \texttt{after} are \texttt{Allen
  Algebra} \cite{allen84} operators, which \eu supports to specify
temporal relations between tokens (specifically between their start
and end timepoints). The algebra is particularly effective in dealing
with interval arithmetic; its elements are summarized in
Fig. \ref{fig:allen-algebra}

\begin{figure}[!t]
\centering
\includegraphics[scale=0.4]{figs/Allen-algebra.pdf}
\caption{\small Temporal relations defined within the planner are
  based on \texttt{Allen Algebra} \cite{allen84} relations shown
  above.}
\label{fig:allen-algebra}
\end{figure}


\subsection{Automated Inference}
\label{sec:europa:inference}

In \eue, all variables and constraints from a problem domain
description are stored inside the \texttt{CRE}.  It provides a
framework where any number of constraint types can collaborate to
perform inference and prune variable domains using Bounds Propagation
and Domain Reduction techniques \cite{marriott98}.  \eu uses a
Propagator pattern which keeps track of a set of constraint instances
of the same type and is responsible for ensuring variables are updated
through inference whenever a relevant change occurs (variable domain
modifications or constraint addition/deletion).

In a planning problem, variable or constraint changes can come
directly from an end user (by introducing new activities or goals and
relating them to the rest of the plan through constraints, by changing
the start or end time of an activity, etc), or from an automated
planner (by expanding subgoals, introducing precedence constraints to
resolve mutual exclusion conflicts, etc). When these changes occur,
each propagator is only able to ensure consistency for the constraints
that are associated with it.  To maintain global consistency, the
\texttt{CRE} implements a variant of the \texttt{AC-3} algorithm
\cite{mackworth77} where propagators are invoked repeatedly until the
constraint network returns to a quiescent state.

\input{constraints-table}

\subsubsection{Constraint Formulation}
\label{sec:europa:constraints}

An \eu user can introduce new constraint types by implementing
specialized constraint and propagator classes. However \eu provides a
built-in constraint library with a range of arithmetic, temporal, set
and resource constraint types so that a large number of problem
domains can be modeled. Tables \ref{tab:calconst}, \ref{tab:setconst},
\ref{tab:objhierarchy} and \ref{tab:misc} show the main constraint
types included in \eus Constraint Library.  Temporal and resource
constraints are especially important to model real-world planning
domains.

\eu uses variables to explicitly represent timepoints for plan actions
and states. Constraints among timepoints provide a natural way to
express domain axioms. For example, in order to state that activity
$A$ must occur before activity $B$ we can say that the end timepoint
of $A$ is $leq$ the start timepoint of $B$.  \cite{dechter91} proposed
that constraints among timepoints can be grouped together to form a
Simple Temporal Network (\texttt{STN}). Such a network can be
transformed into a Distance Graph (\texttt{DG}) where the outward arc
from a node represents the maximum distance from the source node to
the target node.  \kcomment{They} also show that shortest path
algorithms \kcomment{(see \cite{corman} for a review)} could be used
to propagate values in the network and discover a negative cycle:
namely a path from a node to itself that has a path length less than
$0$. If such a cycle exists, the network is \kcomment{provably}
inconsistent. It was further shown that a single-source shortest path
algorithm was sufficient to detect a negative cycle and provide
sufficient propagation to yield a backtrack-free search. \eus
propagator for temporal constraints is an implementation of such a
single-source algorithm. Fig. \ref{fig:stn} illustrates an
\texttt{STN} with $2$ variables and a single constraint along with the
resulting \texttt{DG}.

\begin{figure}[!htb]
  \centering
  \subfloat[\small A Simple Temporal Network (STN). \kcomment{Nodes correspond
  to variables and their domains and arc's the \emph{constraint} or
  distance between them.}]{\label{fig:stn1}\includegraphics[width=0.4\columnwidth]{figs/stn-graph.pdf}}
  \subfloat[\small The resulting distance graph from \ref{fig:stn1}.]{\label{fig:stn2}\includegraphics[width=0.4\columnwidth]{figs/distance-graph.pdf}}
  \caption{\small An illustration of a Simple Temporal Network
    (\texttt{STN}) and its corresponding distance graph.}
  \label{fig:stn}
\end{figure}

Most real-world planning problems need to deal with plans made up of
actions that typically depend upon limited resources (\eg fuel,
storage capacity, battery state of charge, data buffers etc).  % \eu
% provides built-in support for resource computation.
In \eus representation, resource object types come in three forms with
related constraints. \textbf{Reservoir} resources can have both
\texttt{consume(resource,time,quantity)} and
\texttt{produce(resource,time,quantity)} constraints; production and
consumption is instantaneous. \textbf{Reusable} resources on the other
hand, have constraints that use a quantity of the resource for a
specific duration (\texttt{uses(resource,start,duration,quantity)}),
which are then subsequently released. \textbf {Unary} resources are
reusables with capacity$=1$, which \kcomment{accounts for} runtime
savings in comparison to the generic reusable class. Configuration
options are offered such that in addition to the usual constraint
violations when a resource is completely depleted, plan flaws can be
generated whenever a resource level is outside a specific bound, or
when instantaneous production or consumption exceeds a specific
threshold.

Determining whether a resource is the source of a plan flaw or a
constraint violation in general is substantially more difficult in
\eus flexible representation, than just computing a profile of the
resource and checking against some limits.  With temporal flexibility,
a number of resource profiles could be applicable depending on
precisely when each production/consumption event occurs out of a range
of possible values that are in the domain of the variables that
represent the temporal extent for the event.
\cite{Muscettola04,Muscettola06} propose an algorithm where the
variables that represent the time for production/consumption events
are placed in a temporal network, similar to the network used by the
temporal propagator; constraints on the resource can then be seen as
quantities \emph{flowing} through that network. Computing the maximum
flow then, yields the maximum resource usage and thus a lower bound on
the resource level; computing a minimum flow will similarly yield an
upper bound. They show that such upper and lower bound envelopes on
the resource level can be computed in polynomial time
\cite{corman}. Resource envelopes can be useful when trying to
evaluate plan brittleness in the face of changing activity durations
or start times. They can also be useful when searching for plans;
however they are relatively expensive to compute. Therefore their
ability to prune the search space must be weighted against the ability
to search faster \cite{6007772, morris11}. Fig. \ref{fig:resenvelopes}
shows an example of such a resource computation.

\begin{figure}
\centering
\includegraphics[scale=0.2]{figs/europa-resource-envelopes.png}
\caption{\small An example of resource envelopes \cite{Muscettola04,Muscettola06} computed by \eu.}
\label{fig:resenvelopes}
\end{figure}


\subsection{Search in \eu}
\label{sec:europa:search}

Given the above, an automated problem solver can be created using a
\emph{domain model} that describes the variable, object, predicate and
action types that are relevant for the problem, a \emph{problem
  instance} or initial state that consists of variable and object
instances that exist for the entire planning horizon, \emph{temporally
  scoped predicate and action} instances and \emph{temporally scoped
  goals}. This information is retained in \eus \texttt{PDB} so that
inference and search mechanisms can be used to look for a problem
solution.

Since temporal intervals may extend indefinitely in both positive and
negative directions \kcomment{(\eg $[-\infty,+\infty]$)}, for problems
with a temporal dimension it is also common to specify a
\emph{planning horizon} when invoking a solver. Any decisions that
fall completely outside of the horizon can be ignored, ensuring that
the solver is making as few commitments as necessary and reducing plan
generation complexity.  The \emph{planning horizon} is also useful
when dealing with recurrent activities. Consider for instance a model
where a medical checkup has to occur every $3$ months. The user can
model a recurring activity and then use the horizon to ensure that a
finite number of medical checkup activities are generated as part of a
plan.

\subsubsection{Flaw Resolution}
\label{sec:europa:flaws}

\eu provides a built-in solver that performs \emph{Plan Space
  Planning} \cite{ghallab04}; the initial state is considered a
partial plan that needs to be refined toward a solution that achieves
stated goals. The operations to refine the partial plan \texttt{PP} at
any time are:

\begin{enumerate}

\item Find flaws of \texttt{PP}, \ie conditions that prevent it from
  being a solution plan.

\item Select one such flaw.

\item Select a resolver for the flaw.

\item Refine \texttt{PP} by applying the resolver.

\item If an inconsistency is found, try another resolver.

\item If all possible resolvers for a particular flaw fail, return
  failure, otherwise continue until resolving all flaws.

\end{enumerate}
	
The initial partial plan is the state of \eus \texttt{PDB} after the
initial state has been instantiated. This results in a set of
variable, object and token instances. Inference then takes place to
detect flaws in the partial plan. The three kinds of flaws that can be
detected are:

\begin{description}

\item[\textbf{Unbound Variable}:] a variable in the partial plan whose
  domain is not a singleton. Unbound Variables are resolved by value
  selection from their domain.

\item[\textbf{Open Condition}:] an open condition is an
  \texttt{INACTIVE} token which can be generated by explicitly posted
  goals or during token activation when rules may cause the creation
  of \texttt{INACTIVE} slave tokens as described in Section
  \ref{sec:europa:pr}. Open Conditions can be resolved in three ways:

  \begin{description}

  \item[\textbf{Merging}:] An \texttt{INACTIVE} token is merged with a
    matching \texttt{ACTIVE} token already in the plan. A token $a$ is
    said to match another token $a?$ iff $a$ and $a?$ unify
    \cite{russelnorvig} and the temporal constraints involving $a$ are
    satisfied by $a?$. Thus, $a$ and $a?$ can be considered the same
    token without the need to introduce $a$ in the plan. Consequently,
    the domain rules associated with $a$ are not introduced into the
    planning process, since they are already triggered when $a?$ was
    \kcomment{instantiated} in the plan.

  \item[\textbf{Activation}:] A token $a$ is introduced in the current
    plan associating it with the appropriate timeline, without
    choosing a specific time slot; if its timing causes a problem a
    Threat flaw will be triggered (see below).  The domain rules
    associated with $a$ are applied and the subgoal activities
    resulting from those domain rules are introduced as
    \texttt{INACTIVE} tokens.  This results in a number of open
    condition flaws corresponding to the new subgoal activities.

  \item[\textbf{Rejection}:] Some goals may be optional; if so its
    corresponding flaw may be resolved by discarding the
    \texttt{INACTIVE} token.

  \end{description}

\item[\textbf{Threat}:] Once a token has been placed in the partial
  plan it may impact other tokens indirectly through possible
  overlapping requirements on objects. Recall for example that a token
  may belong to objects (\eg timelines) which require a total order
  over their tokens. If any two tokens could possibly overlap (though
  not necessarily), then they pose a threat to each other in terms of
  achieving an extension of the current partial plan which is complete
  and consistent. Similarly, threats may arise where tokens share a
  common resource and their current state might yield extensions of
  the current partial plan which are inconsistent. Threats are
  resolved by imposing ordering constraints among tokens.

\end{description}

Open conditions and threats allow flaw detection and resolution at a
higher-level of abstraction (\ie in terms of objects and tokens) than
that of binding variables as is common in Constraint Satisfaction
Problems. This is advantageous when a solver applies heuristics for
ordering choices since it provides a richer context in which to make
decisions.  Furthermore, it aids in reducing the amount of work done
by a solver so that only the necessary refinements are made,
\kcomment{ensuring} a partial plan with sufficient flexibility. For
example, one can bypass committing unbound timepoint variables since
threats will force a solver to impose ordering restrictions on these
variables.  Thus the planning process may yield partially-ordered
plans for which all possible extensions are provably valid.

The Plan Space Planning algorithm described can be implemented in
multiple ways depending on the approach chosen for flaw and resolver
selection and for backtracking. \eus built-in solver implements a
chronological backtracking algorithm that is summarized in Algorithm
\ref{alg:europa:solve}.


\begin{algorithm}
\KwIn{PartialPlan $plan$}
\KwOut{\texttt{true} if a plan solution was found, \texttt{false} otherwise}
\Begin{
  \lIf{isInconsistent(plan)}{\Return \texttt{false}\;}\label{li:propagate}
  \BlankLine
  Flaw $flaw \leftarrow chooseFlaw(plan)$ \; \label{li:selectflaw}
  \lIf{ $\emptyset = flaw$ }{\Return \texttt{true} \;} \label{li:noflaw}
  \BlankLine
  DecisionPoint $decision \leftarrow makeDecisionPoint(flaw, plan)$ \comment{\{\emph{potential branching point(s)}\}}\;\label{li:decisionpt}
  \While{ $decision.hasNext()$ }{ \label{li:decisionloop}
    PartialPlan $pp \leftarrow decision.executeNext()$ \; \label{li:decide}
    \lIf{ $solve(pp)$ }{ \Return \texttt{true} \; } \label{li:recurse}
    \lElse{ $decision.undo()$ \comment{\{\emph{possible backtracking point}\}}\; } \label{li:backtrack}
   }
   \Return \texttt{false} \; \label{li:noplan}
 }
\caption{$\mathrm{bool} ~ solve(plan)$\kcomment{: To deliberate and
    generate partial plans}}
\label{alg:europa:solve}
\end{algorithm}

The algorithm takes as input a partial plan $p$ and returns true if a
complete and consistent refinement of $p$ could be found (or if $p$ is
initially complete and consistent) and false otherwise. Briefly the
algorithm is described as:

\begin{description}

\item[Line \textbf{\ref{li:propagate}}:] Propagate the constraints to
  test for inconsistency. If inconsistent, then return false since no
  refinements to $p$ can yield a consistent plan.

\item[Line \textbf{\ref{li:selectflaw}}:] Choose a flaw from the set
  of available flaws.

\item[Line \textbf{\ref{li:noflaw}}:] If there are no flaws, then $p$
  is complete and terminate with success.

\item[Line \textbf{\ref{li:decisionpt}}:] Formulate a decision point
  which is a branch in the search space. Each choice is a particular
  refinement operation and the \texttt{DecisionPoint} collects all
  possible refinement operations for the given flaw.

\item[Line \textbf{\ref{li:decisionloop}}:] Keep trying until the
  chosen flaw is resolved, or until there are no further resolvers to
  try.

\item[Line \textbf{\ref{li:decide}}:] A new partial plan is obtained
  by application of a refinement operator. Note that the ordering over
  refinement operators to select is a non-deterministic step.

\item[Line \textbf{\ref{li:recurse}}:] Recursive call to solve the
  new planning problem. If successful, then success.

\item[Line \textbf{\ref{li:backtrack}}:] Otherwise, retract the last
  refinement operation and move on to try the next.

\item[Line \textbf{\ref{li:noplan}}:] Arriving here implies all
  options to resolve the flaw have been exhausted, including the case
  where no options were available initially. Thus the problem is
  insoluble.

\end{description}

Algorithm \ref{alg:europa:solve} provides for a sound and complete
search, assuming that no flaws or available refinement operators are
pruned unnecessarily.  Dead-ends in the search are discovered through
constraint propagation, a vehicle for evaluating the consistency of a
partial plan and also for filtering infeasible values from
consideration prior to commitment. Consistency testing is initiated by
the \texttt{isInconsistent} procedure.  The algorithm permits a
heuristically controlled search by applying orderings for
\texttt{chooseFlaw} and \texttt{makeDecisionPoint} resulting in a
chronologically-backtracked search. Heuristics can be implemented by
applying ordering/filtering policies for \texttt{chooseFlaw} and
\texttt{makeDecisionPoint}, for instance, by dealing with earliest
flaws first, or by making planning decisions (open condition flaws)
before scheduling decision (threats).

It should be emphasized that while this algorithm is commonly employed
by applications that embed \eue, it is only one of many that could be
implemented. As an example, consider the solver in Algorithm
\ref{algo:n-queens} for the $N$-Queens problem, where an integer
variable V$_i$ represents the queen in column $i$; V$_1$ $= 3$ implies
that the variable on column $1$ is placed on row $3$.  Non-attack
constraints are posted as arithmetic constraints among the V$_i$
variables to ensure that all the rows and diagonals contain only one
queen. The \texttt{CRE} can be used to compute the non-attack
constraint violations, with \texttt{ce.getViolations()} a call on the
\eu API. The \texttt{CRE} can also be used to pick the queen that has
the most violations in \texttt{getQueenWithMaxViolation()} and to look
ahead and see what moves are possible for a queen that would remove
its violations in \texttt{getMoves()}.

In similar fashion, the constraint violation and flaw reporting
mechanisms that \eu provides can be used as building blocks that
specialized or general purpose search algorithms can use to construct
plans.

\begin{algorithm}
  \KwIn{ConstraintEngine $ce$}
  \KwIn{int $maxIter$}
  \Begin{
    int $curIter \leftarrow 0$ \;
    \While{$\left( ce.getViolations() > 0 \right) ~ \& ~ \left( curIter <
        maxIter \right)$ }{
      Variable $queenToMove \leftarrow getQueenWithMaxViolation(ce)$
      \;
      SortedSet$<$int$> moves \leftarrow getMoves(ce, queenToMove,
      curPos)$ \;
      bool $moved \leftarrow $ \texttt{false} \;
      \ForEach{int $newPos$ of $moves$}{
        $moved \leftarrow tryMove(queenToMove, curPos, newPos)$\;
        \lIf{$moved$}{ \textbf{break} \; }
      }
      \lIf{$! moved$}{
        $forceMove(queenToMove, curPos, moves.first())$ \;
      }
      $checkSolution()$ \tcp*{Evaluate if a new best solution}
      $curIter$\texttt{++} \;
    }
  }
  \caption{$solveNQueens(ce, maxIter)$\kcomment{: An $N$-Queens solver}}
  \label{algo:n-queens}
\end{algorithm}


%%% Local Variables: 
%%% mode: latex
%%% TeX-master: "setobook"
%%% End: 


 